{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # * sklearn 라이브러리에서 간단한 분류 모델\n",
    "\n",
    "\n",
    "## - SVM ( Support Vector Machine )\n",
    "  \n",
    "\n",
    "* svm(서포트벡터머신:분류, 회귀) 알고리즘 : 분류(SVC), 회귀(SVR)\n",
    "\t\t- fit() : 학습기계에 데이터를 학습시키는 메소드\n",
    "\t\t- predict() : 데이터를 넣고 예측하는 메소드\n",
    "\t\t- metrics.accuracy_score() : 정확도 측정 (검증)\n",
    "\n",
    "<img src='./imgs/svm.png' width='500' height='380'>\n",
    "\n",
    "    \n",
    "\n",
    "----------------------------------------------------\n",
    "\n",
    "### + 사용알고리즘 SVC ( 분류 )\n",
    "\n",
    "    from sklearn import svm\n",
    "\n",
    "    model = svm.SVC()\n",
    "\n",
    "    * 매개변수\n",
    "    \n",
    "        1) gamma\n",
    "            - 데이터포인트 사이의 거리는 가우시안 커널에 의해 계산되는데, 가우시안 커널의 폭을 제어하는 매개변수    \n",
    "            - 하나의 훈련 샘들이 미치는 영향의 범위를 결정\n",
    "            - gamma값이 크면 모델이 더 복잡해진다\n",
    "        2) C\n",
    "            - 각 포인트의 중요도를 제한\n",
    "            \n",
    "---            \n",
    "            \n",
    "### + 머신러닝 프로그램 절차\n",
    "\n",
    "    (1) 데이타 읽기\n",
    "    \n",
    "    (2) 데이터와 레이블 분리 변수 선언 - 데이타와 타켓(레이블)\n",
    "         * 데이타 분리 (열)\n",
    "        \n",
    "    (3) 학습데이타와 검증 데이타 분류 - train_test_split()\n",
    "         * 데이타 분리 (행)\n",
    "    \n",
    "    (4) 알고리즘 적용하여  학습 - fit()\n",
    "    \n",
    "    (5) 예측 - predict()\n",
    "    \n",
    "    (6) 정확도 - accuracy_score()\n",
    "    \n",
    "    (7) 검증하기 - score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\tjdgh\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.post5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall sklearn\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  1. 데이타로딩\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 2. 데이터와 레이블 분리 변수 선언\n",
    "X= iris.data\n",
    "y= iris.target\n",
    "iris['data'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.  2.  3.5 1. ]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [6.3 2.7 4.9 1.8]]\n",
      "[[5.8 2.8 5.1 2.4]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.1 2.8 4.  1.3]]\n",
      "[1 2 2 2 2 1 2 1 1 2]\n",
      "[2 1 0 2 0 2 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 3. 데이터셋 분리 ( 학습데이타:검증데이타 = 7:3 )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "print(X_train[:10])\n",
    "print(X_test[:10])\n",
    "print(y_train[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor']\n",
      "훈련점수:  0.9809523809523809\n",
      "테스트점수:  0.9777777777777777\n",
      "정확도: 0.9777777777777777\n",
      "['virginica']\n"
     ]
    }
   ],
   "source": [
    "# 4. 알고리즘 데이터를 학습시키고 예측하기 ( 테스트 데이타로 예측 )\n",
    "\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "model = svm.SVC(gamma='auto')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. 예측하기\n",
    "newData = np.array([[5.,  2.  ,3.5 ,1. ]])\n",
    "result = model.predict(newData)\n",
    "print(iris['target_names'][result])\n",
    "\n",
    "# 6. 정확도 ( 예측값과 테스트라벨의 차이 )\n",
    "\n",
    "print('훈련점수: ', model.score(X_train, y_train))\n",
    "print('테스트점수: ', model.score(X_test, y_test))\n",
    "\n",
    "# 7. 검증하기 \n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "print('정확도:', np.mean(y_test == y_predict))\n",
    "\n",
    "\n",
    "newdata = np.array([[6.5 ,3.  ,5.5 ,1.8]])\n",
    "result = model.predict(newdata)\n",
    "print(iris['target_names'][result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "\n",
    "# [참고만] 일반 데이타셋인 경우  \n",
    "\n",
    "#### 학습데이타와 테스트데이타로 나누고 데이타 분리한다면\n",
    "\n",
    "###   ## train_test_split 함수 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.6, 3.0, 6.6, 2.1], [6.3, 2.9, 5.6, 1.8], [7.2, 3.2, 6.0, 1.8], [4.9, 3.6, 1.4, 0.1], [5.5, 2.4, 3.7, 1.0], [4.6, 3.1, 1.5, 0.2], [6.0, 2.7, 5.1, 1.6], [5.6, 3.0, 4.5, 1.5], [5.7, 3.8, 1.7, 0.3], [5.6, 2.5, 3.9, 1.1]]\n",
      "['\"Virginica\"', '\"Virginica\"', '\"Virginica\"', '\"Setosa\"', '\"Versicolor\"', '\"Setosa\"', '\"Versicolor\"', '\"Versicolor\"', '\"Setosa\"', '\"Versicolor\"']\n",
      "[[5.0, 3.4, 1.6, 0.4], [5.2, 2.7, 3.9, 1.4], [6.1, 2.9, 4.7, 1.4], [6.8, 2.8, 4.8, 1.4], [6.1, 3.0, 4.6, 1.4], [4.8, 3.1, 1.6, 0.2], [5.8, 4.0, 1.2, 0.2], [6.3, 3.4, 5.6, 2.4], [6.6, 3.0, 4.4, 1.4], [7.2, 3.0, 5.8, 1.6]]\n",
      "['\"Setosa\"', '\"Versicolor\"', '\"Versicolor\"', '\"Versicolor\"', '\"Versicolor\"', '\"Setosa\"', '\"Setosa\"', '\"Virginica\"', '\"Versicolor\"', '\"Virginica\"']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import random, re   # re : 정규표현식\n",
    "\n",
    "# 1. 붓꽃 데이터 읽어 들이기\n",
    "csv = []\n",
    "\n",
    "with open('../data/iris/iris.csv','r', encoding='utf-8') as fp: \n",
    "\t# iris.csv 파일을 r(읽기모드)로 열다\n",
    "\tfor line in fp: # 한 줄씩 읽어오기\n",
    "\t\tline = line.strip()   # 줄바꿈 제거\n",
    "\t\tcols = line.split(',')# 쉼표로 컬럼을 구분\n",
    "\n",
    "\t\t# 문자열 데이터를 숫자(실수)로 변환하기\n",
    "        # 파이썬의 삼항연산자\n",
    "        # (값)=(True일 때의 값) if (조건) else (False일 때의 값)\n",
    "        \n",
    "\t\tfn = lambda n:float(n) if re.match(r'^[0-9\\.]+$',n) else n\n",
    "\t\tcols = list(map(fn, cols))\n",
    "\t\tcsv.append(cols)\n",
    "\t\t# 추후에 pandas로 간편하게 데이타셋 읽어올 수 있음\n",
    "\n",
    "\n",
    "# 헤더(컬럼명) 제거\n",
    "del csv[0]\n",
    "\n",
    "# 품종별로 데이타 순서로 있기에 학습데이타와 테스트데이타를 나누기 전에 섞는다\n",
    "# 그래야 각각의 데이타에 품종별로 골로루 데이타가 들어가도록\n",
    "random.shuffle(csv)\n",
    "\n",
    "# 학습데이타와 테스트 데이터로 분리하기\n",
    "total_len = len(csv)\n",
    "train_len = int(total_len*2/3) # 학습데이타 2/3, 테스트데이터 1/3\n",
    "\n",
    "train_data=[]\n",
    "train_label=[]\n",
    "\n",
    "test_data=[]\n",
    "test_label=[]\n",
    "\n",
    "\n",
    "for i in range(total_len):\n",
    "\tdata=csv[i][0:4]\n",
    "\tlabel=csv[i][4]\n",
    "\tif i < train_len:\n",
    "\t\ttrain_data.append(data)\n",
    "\t\ttrain_label.append(label)\n",
    "\telse:\n",
    "\t\ttest_data.append(data)\n",
    "\t\ttest_label.append(label)\n",
    "\n",
    "print(train_data[:10])\n",
    "print(train_label[:10])\n",
    "print(test_data[:10])\n",
    "print(test_label[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 분류모델을 이용하여 학습데이타를 넣고 훈련하고 예측한다\n",
    "clf = svm.SVC(gamma='auto') \n",
    "clf.fit(train_data, train_label)   # 학습하기\n",
    "\n",
    "pre_label = clf.predict(test_data) # 예측하기\n",
    "\n",
    "# 검증하기 - 정확도 \n",
    "ac_score = metrics.accuracy_score(test_label, pre_label)\n",
    "print(ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
